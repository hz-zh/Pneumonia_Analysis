{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "#\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D,Conv2D, MaxPooling2D,BatchNormalization, Dropout, Input, LeakyReLU, UpSampling2D, Conv2DTranspose\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Kaggle API Token\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "\n",
    "# Setup Kaggle API\n",
    "!pip install kaggle --quiet\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download the Dataset\n",
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
    " # Extract the Dataset\n",
    "!unzip -q chest-xray-pneumonia.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the directory path for training and testing images\n",
    "base_dir = './chest_xray'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Preprocessing the images - setting up image data generators\n",
    "\n",
    "batch_size = 16\n",
    "image_size = 178\n",
    "\n",
    "# Limit data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20,\n",
    "                           width_shift_range=0.2, height_shift_range=0.2)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(image_size, image_size), \n",
    "                                       batch_size=batch_size, class_mode='binary')\n",
    "val_generator = val_datagen.flow_from_directory(val_dir, target_size=(image_size, image_size), \n",
    "                                      batch_size=batch_size, class_mode='binary')\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(image_size, image_size), \n",
    "                                      batch_size=batch_size, class_mode='binary')\n",
    "\n",
    "# Use tf.data.Dataset for efficient data loading\n",
    "def generator_wrapper(generator):\n",
    "   for x_batch, y_batch in generator:\n",
    "      yield (x_batch, x_batch)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "   lambda: generator_wrapper(train_generator),\n",
    "   output_signature=(\n",
    "      tf.TensorSpec(shape=(None, image_size, image_size, 3), dtype=tf.float32),\n",
    "      tf.TensorSpec(shape=(None, image_size, image_size, 3), dtype=tf.float32))\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "   lambda: generator_wrapper(val_generator),\n",
    "   output_signature=(\n",
    "      tf.TensorSpec(shape=(None, image_size, image_size, 3), dtype=tf.float32),\n",
    "      tf.TensorSpec(shape=(None, image_size, image_size, 3), dtype=tf.float32))\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "   lambda: generator_wrapper(test_generator),\n",
    "   output_signature=(\n",
    "      tf.TensorSpec(shape=(None, image_size, image_size, 3), dtype=tf.float32),\n",
    "      tf.TensorSpec(shape=(None, image_size, image_size, 3), dtype=tf.float32))\n",
    ").prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D,Conv2D, MaxPooling2D,BatchNormalization, Dropout, Input, LeakyReLU, UpSampling2D, Conv2DTranspose\n",
    "\n",
    "\n",
    "# Encoder\n",
    "conv_encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape([image_size, image_size, 3], name=\"input\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"), \n",
    "    tf.keras.layers.MaxPool2D(pool_size=2), # output: 112x112x16\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"), \n",
    "    tf.keras.layers.MaxPool2D(pool_size=2), # output: 56x56x32\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"), \n",
    "    tf.keras.layers.MaxPool2D(pool_size=2), # output: 28x28x64\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"), \n",
    "    tf.keras.layers.MaxPool2D(pool_size=2), # output: 14x14x128\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(256, 3, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2), # output: 7x7x256\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(60, 3, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalAvgPool2D() # output: 60\n",
    "])\n",
    "\n",
    "# Decoder\n",
    "conv_decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(28 * 28 * 256),\n",
    "    tf.keras.layers.Reshape((28, 28, 256)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2DTranspose(256, 3, strides=2, padding=\"same\", activation=\"relu\"), # output: 56x56x256\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2DTranspose(128, 3, strides=2, padding=\"same\", activation=\"relu\"), # output: 112x112x128\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2DTranspose(64, 3, strides=2, padding=\"same\", activation=\"relu\"), # output: 224x224x64\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2DTranspose(32, 3, strides=1, padding=\"same\", activation=\"relu\"), # output: 224x224x32\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2DTranspose(16, 3, strides=1, padding=\"same\", activation=\"relu\"), # output: 224x224x16\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2DTranspose(3, 3, strides=1, padding=\"same\", activation=\"sigmoid\"), # output: 224x224x3\n",
    "    tf.keras.layers.Reshape([image_size, image_size, 3], name=\"output\")\n",
    "])\n",
    "\n",
    "# Autoencoder\n",
    "conv_ae = tf.keras.Sequential([conv_encoder, conv_decoder])\n",
    "\n",
    "\n",
    "conv_ae.compile(\n",
    "    loss=\"mean_squared_error\", \n",
    "    # Use nadam with a 0.01 learning rate\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=0.01),\n",
    "     metrics=[tf.keras.metrics.MeanSquaredError(),'accuracy'])\n",
    "\n",
    "conv_ae.build(input_shape=(None, image_size, image_size, 3))\n",
    "conv_ae.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callbacks\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('conv_ae.keras', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = conv_ae.fit(\n",
    "   train_dataset, \n",
    "   epochs=10, \n",
    "   validation_data=test_dataset,\n",
    "   steps_per_epoch=len(train_generator),\n",
    "   validation_steps=len(val_generator),\n",
    "   callbacks=[\n",
    "      early_stopping,\n",
    "      model_checkpoint,\n",
    "      reduce_lr\n",
    "   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the encoded images\n",
    "def visualize(img, encoder, decoder):\n",
    "   encoded = encoder.predict(img[None])[0]\n",
    "   decoded = decoder.predict(encoded[None])[0]\n",
    "   plt.figure(figsize=(10, 5))\n",
    "   plt.subplot(1, 3, 1)\n",
    "   plt.title(\"Original\")\n",
    "   plt.imshow(img)\n",
    "   plt.axis('off')\n",
    "   plt.subplot(1, 3, 2)\n",
    "   plt.title(\"Encoded\")\n",
    "   plt.imshow(encoded)\n",
    "   plt.axis('off')\n",
    "   plt.subplot(1, 3, 3)\n",
    "   plt.title(\"Decoded\")\n",
    "   plt.imshow(decoded)\n",
    "   plt.axis('off')\n",
    "   plt.show()\n",
    "\n",
    "# Visualize the images\n",
    "for img, _ in test_dataset.take(5):\n",
    "   visualize(img[0], conv_encoder, conv_decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "   x = list(range(len(history.history['accuracy']))),\n",
    "   y = history.history['accuracy'],\n",
    "   mode = 'lines',\n",
    "   name = 'Train'\n",
    ")\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "   x = list(range(len(history.history['val_accuracy']))),\n",
    "   y = history.history['val_accuracy'],\n",
    "   mode = 'lines',\n",
    "   name = 'Test'\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Model Accuracy',\n",
    "           xaxis = dict(title = 'Epoch'),\n",
    "           yaxis = dict(title = 'Accuracy'),\n",
    "           )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "go.Figure(fig).show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
