{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C--nAyUBUb6"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fUI9MjJ8FTv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D,Conv2D, MaxPooling2D,BatchNormalization, Dropout, Input, LeakyReLU\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4MaOHUuBcOz"
   },
   "source": [
    "# Kaggle API Token\n",
    "\n",
    "1. Go to your Kaggle account, click on your profile picture (top right), and go to \"Account\" from the menu.\n",
    "2. Scroll down to the \"API\" section and click on \"Create New API Token\". This will download a kaggle.json file containing your API credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "OJk2ShSb5aUI",
    "outputId": "6506bd21-fd43-4b9e-b6ef-2cfa2f9dca4f"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTeVX0ZTCEYR"
   },
   "source": [
    "# Setup Kaggle API\n",
    "Set up the Kaggle API and ensure the kaggle.json file is in the correct location with the appropriate permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCf3t47C5dAI"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle --quiet\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8k7rrJrfCNHV"
   },
   "source": [
    "# Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-tar85v5dDH",
    "outputId": "121e1aab-aee0-455f-a1ab-b4d143e07315"
   },
   "outputs": [],
   "source": [
    "#kaggle datasets download -d [username/dataset-name]\n",
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jX_WWN8DCkPa"
   },
   "source": [
    " # Extract the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCIgEaCE5dGn"
   },
   "outputs": [],
   "source": [
    "!unzip -q chest-xray-pneumonia.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYfOP0IlCy5l"
   },
   "source": [
    "# List Directories at the Root of the Unzipped Folder\n",
    "Assuming the dataset is unzipped into a folder named chest_xray in the current working directory, you can list its contents using os.listdir()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xl_RlR-r5dJH",
    "outputId": "35a29a51-29aa-4616-cbee-b1b9546640d2"
   },
   "outputs": [],
   "source": [
    "root_dir = 'chest_xray'\n",
    "os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSj5Nk4pC85H"
   },
   "source": [
    "# Explore Further and List Files\n",
    "To list the files in a specific directory, such as the training set for normal chest X-rays, you might do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3Bly9Ck8Ypu",
    "outputId": "191ecaaf-dda7-4449-c21e-9bb830952307"
   },
   "outputs": [],
   "source": [
    "train_normal_dir = os.path.join(root_dir, 'train', 'NORMAL')\n",
    "train_normal_files = os.listdir(train_normal_dir)\n",
    "print(train_normal_files[:4])  # List the first 10 file names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D64W49zb8Yue",
    "outputId": "811a0e8a-6f93-47c6-c1ab-4d0a6daeb0f1"
   },
   "outputs": [],
   "source": [
    "train_pneumonia_dir = os.path.join(root_dir, 'train', 'PNEUMONIA')\n",
    "train_pneumonia_files = glob.glob(train_pneumonia_dir + '/**/*.jpeg', recursive=True)\n",
    "print(train_pneumonia_files[:10])  # List the first 10 file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U85EXSLsDQIP"
   },
   "source": [
    "# Display Multiple Images in a Grid\n",
    "To display multiple images in a grid, you can use a loop. Here's an example of displaying the first few images from a list of image paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "VkeCykLq8Yxd",
    "outputId": "af7fd657-8bb3-4b3c-9f01-9359c6bd5288"
   },
   "outputs": [],
   "source": [
    "# Example: Display the first 3 pneumonia images from the training set\n",
    "num_images = 3\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 12))  # Create a grid of 3x3\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < num_images:\n",
    "        image_path = train_pneumonia_files[i]\n",
    "        image = Image.open(image_path)\n",
    "        ax.imshow(image, cmap='gray')  # Use cmap='gray' if it's a grayscale image\n",
    "        ax.set_title(f'Image {i+1}')\n",
    "        ax.axis('off')  # Hide the axes\n",
    "    else:\n",
    "        ax.axis('off')  # Hide axes for empty subplots\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2sWwJcPDjd_"
   },
   "source": [
    "# Data Preprocessing\n",
    "Use ImageDataGenerator to load your data and apply preprocessing required for ResNet50. You might need to adjust target_size based on the input size that ResNet50 expects (224x224). You can change the images to grayscale as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01bpL_Vj8-Y1"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(root_dir, 'train')\n",
    "val_dir = os.path.join(root_dir, 'val')\n",
    "test_dir = os.path.join(root_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move 24 images from the training set to the validation set\n",
    "num_images = 24\n",
    "\n",
    "normal_images = train_normal_files[:num_images]\n",
    "pneumonia_images = train_pneumonia_files[:num_images]\n",
    "\n",
    "for image in normal_images:\n",
    "      source = os.path.join(train_normal_dir, image)\n",
    "      dest = os.path.join(val_dir, 'NORMAL', image)\n",
    "      os.rename(source, dest)\n",
    "\n",
    "for image in pneumonia_images:\n",
    "      source = image\n",
    "      dest = os.path.join(val_dir, 'PNEUMONIA', os.path.basename(image))\n",
    "      os.rename(source, dest)\n",
    "\n",
    "# Check the number of images in the training and validation sets\n",
    "num_train_normal = len(os.listdir(train_normal_dir))\n",
    "num_train_pneumonia = len(os.listdir(train_pneumonia_dir))\n",
    "\n",
    "num_val_normal = len(os.listdir(os.path.join(val_dir, 'NORMAL')))\n",
    "num_val_pneumonia = len(os.listdir(os.path.join(val_dir, 'PNEUMONIA')))\n",
    "print(f'Training set: Normal - {num_train_normal}, Pneumonia - {num_train_pneumonia}')\n",
    "print(f'Validation set: Normal - {num_val_normal}, Pneumonia - {num_val_pneumonia}')\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the preprocessing function\n",
    "def preprocess(image, label):\n",
    "    image = preprocess_input(image)\n",
    "    # apply random brightness augmentation\n",
    "    image = tf.image.random_brightness(image, 0.1)\n",
    "  # apply random contrast augmentation\n",
    "    image = tf.image.random_contrast(image, 0.4, 0.6)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Create a dataset from the directory\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='binary',\n",
    "    preprocessing_function=preprocess\n",
    ")\n",
    "\n",
    "# Apply preprocessing, augmentation and prefetching\n",
    "train_dataset = train_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Do the same for the validation dataset\n",
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='binary'\n",
    ")\n",
    "val_dataset = val_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "all_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    root_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='binary'\n",
    ")\n",
    "all_data = all_data.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "all_data = all_data.prefetch(tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load VGG16 trained on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 VGG_custom_head without head (headless)\n",
    "vgg_ = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "#vgg_.trainable = False\n",
    "vgg_.trainable = True\n",
    "\n",
    "# Define input layer (adjust the shape based on your input images)\n",
    "input_tensor = Input(shape=(224, 224, 3), name='input_1')\n",
    "\n",
    "# Pass input through VGG16 base VGG_custom_head\n",
    "x = vgg_(input_tensor, training=False)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', name='Conv2D_1')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu', name='Dense_1')(x)\n",
    "x = Dropout(0.5, name='Dropout_1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "VGG_output = Dense(1, activation='sigmoid', name='Output_1')(x)\n",
    "\n",
    "# Create the VGG_custom_head model\n",
    "VGG_custom_head = Model(inputs=input_tensor, outputs = VGG_output, name='VGG16_transfer')\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "# Fine-tune layers the last 4 layers\n",
    "number_of_tune_layers = 2\n",
    "for layer in vgg_.layers[:-number_of_tune_layers]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the VGG_custom_head\n",
    "VGG_custom_head.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Print VGG_custom_head and the base summary\n",
    "vgg_.summary()\n",
    "VGG_custom_head.summary()\n",
    "tf.keras.utils.plot_model(VGG_custom_head, show_shapes=True)\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "VGG_history = VGG_custom_head.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbfydqkFFPLa"
   },
   "source": [
    "# Load the Pre-trained ResNet50 Model\n",
    "Load ResNet50 with pre-trained weights from ImageNet, excluding the top (fully connected) layers. Set input_shape as required by ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8TcinbMZAFLz",
    "outputId": "e32fd247-b0c0-4360-fb4e-36d483012597"
   },
   "outputs": [],
   "source": [
    "resnet50_ = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# Fine-tune layers the last 4 layers\n",
    "number_of_tune_layers = 18\n",
    "for layer in resnet50_.layers[:-number_of_tune_layers]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r16u1oSKFVO2"
   },
   "source": [
    "# Add Custom Layers on Top of ResNet50\n",
    "Now, create a sequential model, add the pre-trained base model, and then add your custom layers on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZMVUsQcAFQS",
    "outputId": "c7b11d07-8796-4deb-e22b-1f886b4e36b5"
   },
   "outputs": [],
   "source": [
    "# Add your sequential model \n",
    "\n",
    "# Create a new model on top\n",
    "Res_input = Input(shape=(224, 224, 3))\n",
    "x = resnet50_(Res_input, training=False)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (5, 5), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "Res_outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "Res_model = Model(Res_input, Res_outputs)\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "# Compile the model\n",
    "Res_model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "      metrics=['accuracy']\n",
    "   )\n",
    "\n",
    "resnet50_.summary()\n",
    "Res_model.summary()\n",
    "\n",
    "#tf.keras.utils.plot_model(Res_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XeyYOnAAMLy",
    "outputId": "aaffcd50-c99a-4010-eb07-0f2019e3c81d"
   },
   "outputs": [],
   "source": [
    "# Fit your model\n",
    "Res_history = Res_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=30,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ot0FK7OyEppO"
   },
   "source": [
    "# Prepare the Test Data\n",
    "First, prepare your test data using ImageDataGenerator, similar to how you prepared the training and validation data. Make sure to use the preprocess_input function from ResNet50 for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUM7bAWiBFOs",
    "outputId": "2ace8307-42a9-401e-e61d-a16f7beb7145"
   },
   "outputs": [],
   "source": [
    "# Add your code by following the example in the Data Preprocessing section.\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    label_mode='binary'\n",
    ")\n",
    "test_dataset = test_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7XgYs3MEjv-"
   },
   "source": [
    "# Evaluate the Model\n",
    "Use the evaluate method to test the model's performance on the test set. Your model must have at least 90% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1wx_BWSBFSq",
    "outputId": "6b8d1f8f-d888-4629-d935-127213a61e4b"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "VGG_custom_head.evaluate(test_dataset, verbose=1)\n",
    "Res_model.evaluate(test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgiuZjadEcLS"
   },
   "source": [
    "# Plot Learning Curves\n",
    "To visualize the learning curves (accuracy and loss for both training and validation), you can plot them using matplotlib. This helps in understanding overfitting, underfitting, or if the model is learning well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "qMcK7l-FAFzX",
    "outputId": "d2fd1dc6-8375-45c1-d2d4-0a38c57f6cd3"
   },
   "outputs": [],
   "source": [
    "# Add your code here or use tensorboard\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create traces\n",
    "trace1 = go.Scatter(\n",
    "   x=list(range(len(VGG_history.history['accuracy']))),\n",
    "   y=VGG_history.history['accuracy'],\n",
    "   mode='lines',\n",
    "   name='VGG16 Training Accuracy'\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "   x=list(range(len(VGG_history.history['val_accuracy']))),\n",
    "   y=VGG_history.history['val_accuracy'],\n",
    "   mode='lines',\n",
    "   name='VGG16 Validation Accuracy'\n",
    ")\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "   x=list(range(len(Res_history.history['accuracy']))),\n",
    "   y=Res_history.history['accuracy'],\n",
    "   mode='lines',\n",
    "   name='ResNet50 Training Accuracy'\n",
    ")\n",
    "\n",
    "trace4 = go.Scatter(\n",
    "   x=list(range(len(Res_history.history['val_accuracy']))),\n",
    "   y=Res_history.history['val_accuracy'],\n",
    "   mode='lines',\n",
    "   name='ResNet50 Validation Accuracy'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2, trace3, trace4]\n",
    "\n",
    "# Define layout\n",
    "layout = go.Layout(\n",
    "   title='Training and Validation Accuracy for VGG16 and ResNet50',\n",
    "   xaxis=dict(title='Epoch'),\n",
    "   yaxis=dict(title='Accuracy'),\n",
    ")\n",
    "\n",
    "# Define figure\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# Plot the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaTbjbibjhmF"
   },
   "source": [
    "# Create a Customized Model and Evaluate It.\n",
    " Your customized model must have at least 90% accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here\n",
    "\n",
    "input_tensor = Input(shape=(224, 224, 3), name='input_01')\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', name='block_1_conv_1')(input_tensor)\n",
    "x = BatchNormalization(name='block_1_batchNorm')(x)\n",
    "x = MaxPooling2D((2, 2), name='block_1_maxPooling')(x)\n",
    "x = Dropout(0.0, name='block_1_dropout')(x)\n",
    "\n",
    "x = Conv2D(16, (5, 5), activation='relu', name='block_2_conv_1')(x)\n",
    "x = BatchNormalization(name='block_2_batchNorm')(x)\n",
    "x = MaxPooling2D((2, 2), name='block_2_maxPooling')(x)\n",
    "x = Dropout(0.1, name='block_2_dropout')(x)\n",
    "\n",
    "x = Conv2D(32, (5, 5), activation='relu', name='block_3_conv_1')(x)\n",
    "x = BatchNormalization(name='block_3_batchNorm')(x)\n",
    "x = MaxPooling2D((2, 2), name='block_3_maxPooling')(x)\n",
    "x = Dropout(0.5, name='block_3_dropout')(x)\n",
    "\n",
    "x = Conv2D(128, (7, 7), activation='relu', name='block_4_conv_1')(x)\n",
    "x = BatchNormalization(name='block_4_batchNorm_1')(x)\n",
    "x = Conv2D(128, (7, 7), activation='relu', name='block_4_conv_2')(x)\n",
    "x = BatchNormalization(name='block_4_batchNorm_2')(x)\n",
    "x = Conv2D(128, (7, 7), activation='relu', name='block_4_conv_3')(x)\n",
    "x = BatchNormalization(name='block_4_batchNorm_3')(x)\n",
    "x = MaxPooling2D((2, 2), name='block_4_maxPooling')(x)\n",
    "x = Dropout(0.5, name='block_4_dropout')(x)\n",
    "\n",
    "x = Flatten(name='Flatten')(x)\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(128, activation='relu',name='fc_1')(x)\n",
    "x = BatchNormalization(name='fc_batchNorm')(x)\n",
    "x = Dropout(0.5, name='block_5_dropout')(x)\n",
    "\n",
    "custom_output = Dense(1, activation='sigmoid',name='output_1')(x)\n",
    "custom_model = Model(inputs=input_tensor, outputs=custom_output, name='custom_model')\n",
    "\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "# Compile the model\n",
    "custom_model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=base_learning_rate),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "custom_model.summary()\n",
    "\n",
    "# Fit your model\n",
    "custom_history = custom_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=30,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "custom_model.evaluate(test_dataset, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here\n",
    "\n",
    "input_tensor = Input(shape=(224, 224, 3), name='input_01')\n",
    "\n",
    "x = Conv2D(32, (5, 5), activation='relu', name='block_1_conv_1')(input_tensor)\n",
    "x = BatchNormalization(name='block_1_batchNorm_1')(x)\n",
    "x = Conv2D(32, (5, 5), activation='relu', name='block_1_conv_2')(x)\n",
    "x = BatchNormalization(name='block_1_batchNorm_2')(x)\n",
    "x = Conv2D(32, (5, 5), activation='relu', name='block_1_conv_3')(x)\n",
    "x = BatchNormalization(name='block_1_batchNorm_3')(x)\n",
    "x = MaxPooling2D((2, 2), name='block_1_maxPooling')(x)\n",
    "x = Dropout(0.5, name='block_1_dropout')(x)\n",
    "\n",
    "x = Conv2D(64, (7, 7), activation='relu', name='block_2_conv_1')(x)\n",
    "x = BatchNormalization(name='block_2_batchNorm_1')(x)\n",
    "x = Conv2D(64, (7, 7), activation='relu', name='block_2_conv_2')(x)\n",
    "x = BatchNormalization(name='block_2_batchNorm_2')(x)\n",
    "x = Conv2D(64, (7, 7), activation='relu', name='block_2_conv_3')(x)\n",
    "x = BatchNormalization(name='block_2_batchNorm_3')(x)\n",
    "x = MaxPooling2D((2, 2), name='block_2_maxPooling')(x)\n",
    "x = Dropout(0.5, name='block_2_dropout')(x)\n",
    "\n",
    "x = Conv2D(128, (7, 7), activation='relu', name='block_4_conv_1')(x)\n",
    "x = BatchNormalization(name='block_4_batchNorm_1')(x)\n",
    "x = Conv2D(128, (7, 7), activation='relu', name='block_4_conv_2')(x)\n",
    "x = BatchNormalization(name='block_4_batchNorm_2')(x)\n",
    "x = Conv2D(128, (7, 7), activation='relu', name='block_4_conv_3')(x)\n",
    "x = BatchNormalization(name='block_4_batchNorm_3')(x)\n",
    "x = MaxPooling2D((2, 2), name='block_4_maxPooling')(x)\n",
    "x = Dropout(0.5, name='block_4_dropout')(x)\n",
    "\n",
    "x = Flatten(name='Flatten')(x)\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(128, activation='relu',name='fc_1')(x)\n",
    "x = BatchNormalization(name='fc_batchNorm')(x)\n",
    "x = Dropout(0.5, name='block_5_dropout')(x)\n",
    "\n",
    "custom_output = Dense(1, activation='sigmoid',name='output_1')(x)\n",
    "custom_model = Model(inputs=input_tensor, outputs=custom_output, name='custom_model')\n",
    "\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "# Compile the model\n",
    "custom_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "custom_model.summary()\n",
    "\n",
    "# Fit your model\n",
    "custom_history = custom_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=30,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "custom_model.evaluate(test_dataset, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ow5cUsJfrP_7"
   },
   "outputs": [],
   "source": [
    "# Use learning curves or tensorboard to visualize the performance of your customized model.\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create traces\n",
    "trace1 = go.Scatter(\n",
    "   x=list(range(len(custom_history.history['accuracy']))),\n",
    "   y=custom_history.history['accuracy'],\n",
    "   mode='lines',\n",
    "   name='Custom Model Training Accuracy'\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "   x=list(range(len(custom_history.history['val_accuracy']))),\n",
    "   y=custom_history.history['val_accuracy'],\n",
    "   mode='lines',\n",
    "   name='Custom Model Validation Accuracy'\n",
    ")\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "   x=list(range(len(custom_history.history['loss']))),\n",
    "   y=custom_history.history['loss'],\n",
    "   mode='lines',\n",
    "   name='Custom Model Training Loss'\n",
    ")\n",
    "\n",
    "trace4 = go.Scatter(\n",
    "   x=list(range(len(custom_history.history['val_loss']))),\n",
    "   y=custom_history.history['val_loss'],\n",
    "   mode='lines',\n",
    "   name='Custom Model Validation Loss'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2, trace3, trace4]\n",
    "\n",
    "# Define layout\n",
    "layout = go.Layout(\n",
    "   title='Training and Validation Accuracy for Custom Model',\n",
    "   xaxis=dict(title='Epoch'),\n",
    "   yaxis=dict(title='Accuracy'),\n",
    ")\n",
    "\n",
    "# Define figure\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# Plot the figure\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit a separate Word or PDF document discussing the performances of the transfer learning model vs. your customized model."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
